<!DOCTYPE html>
<html lang="en-us">
  <head>
    <title>Hadoop2.7.1+Ubuntu16.04安装 - Pinvon&#39;s Blog</title>
    <meta charset="utf-8" />
    <meta name="author" content="Pinvon" />
    <meta name="description" content="&lt;TODO: insert your description here&gt;" />
    <meta name="keywords" content="&lt;TODO: insert your keywords here&gt;" />
    <link rel="stylesheet" href="/media/css/main.css" type="text/css">
    <link rel="stylesheet" href="/media/css/prettify.css" type="text/css">
  </head>
  <body class="container">
    <div>
      <header class="masthead">
        <h1 class="masthead-title"><a href="/">Pinvon&#39;s Blog</a></h1>
        <p>所见，所闻，所思，所想</p>
        <ul>
          <li><a href="/blog/">Blog</a></li>
          <li><a href="/tags/">Tags</a></li>
          <li><a href="/about/">About</a></li>
          <li><a href="https://github.com/pinvondev">GitHub</a></li>
          <li><a href="/rss.xml">RSS</a></li>
        </ul>
        <form method="get" id="searchform" action="//www.google.com/search">
          <input type="text" class="field" name="q" id="s" placeholder="Search">
          <input type="hidden" name="as_sitesearch" value="pinvondev.github.io">
        </form>
      </header>
    </div>

<div>
<div class="post">
<h1>Hadoop2.7.1+Ubuntu16.04安装</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org7721fed">安装SSH 配置SSH免密码登陆</a>
<ul>
<li><a href="#org1dc7554">安装SSH</a></li>
<li><a href="#org83a72a2">配置SSH免密码登陆</a></li>
</ul>
</li>
<li><a href="#org503a166">设置Linux环境变量的方法和区别</a>
<ul>
<li><a href="#org43a2587">通过文件设置</a>
<ul>
<li><a href="#org7c5e0c9">全局环境变量(对所有用户生效)</a></li>
<li><a href="#orgcbca1da">局部环境变量(对单个用户生效)</a></li>
</ul>
</li>
<li><a href="#orgcfb7aee">通过export设置</a></li>
</ul>
</li>
<li><a href="#org1e56808">安装Java环境</a>
<ul>
<li><a href="#orgb3bd6d0">修改系统默认JDK</a></li>
</ul>
</li>
<li><a href="#org0110770">Hadoop 2.7.1单机安装</a>
<ul>
<li><a href="#org1d88175">试跑例子</a></li>
</ul>
</li>
<li><a href="#org363d5cc">Hadoop2.7.1伪分布式安装</a>
<ul>
<li><a href="#org460d439">配置</a></li>
<li><a href="#org7208389">设置HADOOP_HOME</a></li>
<li><a href="#org04f7068">格式化NameNode</a></li>
<li><a href="#org97d9fb6">启动/关闭 Hadoop</a>
<ul>
<li><a href="#org9716476">启动</a></li>
<li><a href="#org8b2ad7c">关闭</a></li>
</ul>
</li>
<li><a href="#org9b1e44f">运行例子</a></li>
<li><a href="#orgf8ac2ad">启动YARN</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-org7721fed" class="outline-2">
<h2 id="org7721fed">安装SSH 配置SSH免密码登陆</h2>
<div class="outline-text-2" id="text-org7721fed">
</div>
<div id="outline-container-org1dc7554" class="outline-3">
<h3 id="org1dc7554">安装SSH</h3>
<div class="outline-text-3" id="text-org1dc7554">
<p>
无论是集群模式还是单节点模式, 都要用到SSH登陆, Ubuntu默认已安装 <code>SSH client</code>, 还需要自己再安装 <code>SSH server</code>.
</p>
<div class="org-src-container">
<pre class="src src-Shell">sudo apt install openssh-server

# 测试 首次登陆要输yes 接着要输密码
ssh localhost

# 退出
exit
</pre>
</div>
</div>
</div>

<div id="outline-container-org83a72a2" class="outline-3">
<h3 id="org83a72a2">配置SSH免密码登陆</h3>
<div class="outline-text-3" id="text-org83a72a2">
<p>
进入终端, 利用 <code>ssh-keygen</code> 生成密钥, 并将密钥加入到授权中.
</p>
<div class="org-src-container">
<pre class="src src-Shell">cd ~/.ssh/
ssh-keygen -t rsa  #  一路回车
cat ./id_rsa.pub &gt;&gt; ./authorized_keys  #  加入授权
</pre>
</div>
<p>
注: 如果之前安装过 <code>Git</code>, 则已经有 <code>id_rsa.pub</code> 文件, 可直接使用.
</p>
</div>
</div>
</div>


<div id="outline-container-org503a166" class="outline-2">
<h2 id="org503a166">设置Linux环境变量的方法和区别</h2>
<div class="outline-text-2" id="text-org503a166">
</div>
<div id="outline-container-org43a2587" class="outline-3">
<h3 id="org43a2587">通过文件设置</h3>
<div class="outline-text-3" id="text-org43a2587">
</div>
<div id="outline-container-org7c5e0c9" class="outline-4">
<h4 id="org7c5e0c9">全局环境变量(对所有用户生效)</h4>
<div class="outline-text-4" id="text-org7c5e0c9">
<p>
<code>/etc/profile</code>: 为系统的每个用户设置环境信息. 当用户登录时, 该文件被执行一次, 从 <code>/etc/profile.d</code> 目录的配置文件中搜集 <code>shell</code> 的设置.
</p>

<p>
<code>/etc/bashrc</code>: 当 <code>bash shell</code> 被打开时, 该文件被读取.
</p>

<p>
<code>/etc/environment</code>: 设置整个系统的环境, 而 <code>/etc/profile</code> 是设置所有用户的环境, 因为有些数据与用户无关, 与系统相关. 如果两个文件中的设置有冲突, 以 <code>/etc/profile</code> 为准.
</p>
</div>
</div>

<div id="outline-container-orgcbca1da" class="outline-4">
<h4 id="orgcbca1da">局部环境变量(对单个用户生效)</h4>
<div class="outline-text-4" id="text-orgcbca1da">
<p>
<code>~/.bash_profile</code> 或 <code>~/.bash_login</code> 或 <code>~/.profile</code>: 当用户登录时, 该文件执行一次.
</p>

<p>
<code>~/.bashrc</code>: 当用户登录且每次打开新的 <code>shell</code> 时, 该文件被读取.
</p>
</div>
</div>
</div>

<div id="outline-container-orgcfb7aee" class="outline-3">
<h3 id="orgcfb7aee">通过export设置</h3>
<div class="outline-text-3" id="text-orgcfb7aee">
<p>
使用 <code>export</code> 设置的变量, 只对当前终端Shell有效, 如果此时新开一个终端, 则无法读取之前通过 <code>export</code> 设置的变量. 适合设置一些临时变量.
</p>
</div>
</div>
</div>

<div id="outline-container-org1e56808" class="outline-2">
<h2 id="org1e56808">安装Java环境</h2>
<div class="outline-text-2" id="text-org1e56808">
<div class="org-src-container">
<pre class="src src-Shell">sudo tar -zxvf jdk-8u161-linux-x64.tar.gz -C /usr/lib/jvm

# 修改环境变量
export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_161
export JRE_HOME=${JAVA_HOME}/jre
export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib
export PATH=${JAVA_HOME}/bin:$PATH
</pre>
</div>
</div>

<div id="outline-container-orgb3bd6d0" class="outline-3">
<h3 id="orgb3bd6d0">修改系统默认JDK</h3>
<div class="outline-text-3" id="text-orgb3bd6d0">
<p>
Ubuntu中默认安装了 <code>openJDK</code>, 我们又安装了 <code>jdk1.8.0_161</code>. 修改系统默认JDK的方式如下:
</p>
<div class="org-src-container">
<pre class="src src-Shell">sudo update-alternatives --display java  # 可看到openjdk的优先级

# 将jdk1.8.0_161的优先级设置成比openjdk的更高
sudo update-alternatives --install /usr/bin/java java /usr/lib/jvm/jdk1.8.0_161/bin/java 300
sudo update-alternatives --install /usr/bin/javac javac /usr/lib/jvm/jdk1.8.0_161/bin/javac 300
sudo update-alternatives --install /usr/bin/jar jar /usr/lib/jvm/jdk1.8.0_161/bin/jar 300
sudo update-alternatives --install /usr/bin/javah javah /usr/lib/jvm/jdk1.8.0_161/bin/javah 300
sudo update-alternatives --install /usr/bin/javap javap /usr/lib/jvm/jdk1.8.0_161/bin/javap 300

# 选择合适的JDK
sudo update-alternatives --config java
# 输入编号
</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-org0110770" class="outline-2">
<h2 id="org0110770">Hadoop 2.7.1单机安装</h2>
<div class="outline-text-2" id="text-org0110770">
<div class="org-src-container">
<pre class="src src-Shell"># 解压到指定目录
tar -zxf ~/下载/hadoop-2.7.1.tar.gz -C ~
cd ~

# 将文件夹改名为hadoop
mv ./hadoop-2.7.1/ ./hadoop

# 查看文件权限
ls -l

# 修改文件权限
sudo chown -R pinvon:pinvon ./hadoop/

# 测试hadoop是否可用
cd hadoop
./bin/hadoop version
</pre>
</div>
</div>

<div id="outline-container-org1d88175" class="outline-3">
<h3 id="org1d88175">试跑例子</h3>
<div class="outline-text-3" id="text-org1d88175">
<div class="org-src-container">
<pre class="src src-Shell"># 查看所有例子
./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar 

# 运行grep例子
mkdir ./input  # 创建输入文件夹
cp ./etc/hadoop/*.xml ./input  # 将配置文件作为输入文件

./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar grep ./input/ ./output 'dfs[a-z.]+'

# 查看结果
cat ./output/*

# 删除输出
rm -r ./output
</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-org363d5cc" class="outline-2">
<h2 id="org363d5cc">Hadoop2.7.1伪分布式安装</h2>
<div class="outline-text-2" id="text-org363d5cc">
</div>
<div id="outline-container-org460d439" class="outline-3">
<h3 id="org460d439">配置</h3>
<div class="outline-text-3" id="text-org460d439">
<p>
伪分布式的意思是, 我们可以在单节点上, 将Hadoop进程以分离的Java进程来运行, 节点既作为NameNode也作为DataNode, 同时, 读取的是HDFS中的文件.
</p>

<p>
Hadoop的配置文件位于 <code>hadoop/etc/hadoop/</code> 中.
</p>

<p>
伪分布式需要修改 <code>core-site.xml</code> 和 <code>hdfs-site.xml</code>.
</p>

<p>
<code>core-site.xml</code> 修改为:
</p>
<div class="org-src-container">
<pre class="src src-XML">&lt;configuration&gt;
  &lt;property&gt;
    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
    &lt;value&gt;file:/home/pinvon/hadoop/tmp&lt;/value&gt;
    &lt;description&gt;Abase for other temporary directories.&lt;/description&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;fs.defaultFS&lt;/name&gt;
    &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;
  &lt;/property&gt;
&lt;/configuration&gt;
</pre>
</div>

<p>
<code>hdfs-site.xml</code> 修改为:
</p>
<div class="org-src-container">
<pre class="src src-XML">&lt;configuration&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.replication&lt;/name&gt;
    &lt;value&gt;1&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
    &lt;value&gt;file:/home/pinvon/hadoop/tmp/dfs/name&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
    &lt;value&gt;file:/home/pinvon/hadoop/tmp/dfs/data&lt;/value&gt;
  &lt;/property&gt;
&lt;/configuration&gt;
</pre>
</div>

<p>
如果要恢复到单机模式, 则把 <code>core-site.xml</code> 中的配置删除即可.
</p>

<p>
<code>hadoop.tmp.dir</code> 是临时目录. <code>fs.defaultFS</code> 是默认文件系统的名称, 通过其可确定文件系统的主机和端口等.
</p>

<p>
<code>dfs.namenode.name.dir</code> 是本地磁盘目录, NameNode存储fsimage文件的地方. <code>dfs.datanode.data.dir</code> 是HDFS数据应该存储Block的地方.
</p>

<p>
更具体的, 可进hadoop文档查看其Configuration内容.
<a href="http://hadoop.apache.org/docs/current/">http://hadoop.apache.org/docs/current/</a>
</p>
</div>
</div>

<div id="outline-container-org7208389" class="outline-3">
<h3 id="org7208389">设置HADOOP_HOME</h3>
<div class="outline-text-3" id="text-org7208389">
<p>
这一步不是必须的, 但是不设置, 在启动Hadoop时有可能会出错. 打开 <code>~/.bashrc</code>
</p>
<div class="org-src-container">
<pre class="src src-Shell">export HADOOP_HOME=/home/pinvon/hadoop
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/nativeexport 
</pre>
</div>

<p>
<code>source ~/.bashrc</code>
</p>
</div>
</div>

<div id="outline-container-org04f7068" class="outline-3">
<h3 id="org04f7068">格式化NameNode</h3>
<div class="outline-text-3" id="text-org04f7068">
<div class="org-src-container">
<pre class="src src-Shell">./bin/hdfs namenode -format
</pre>
</div>

<p>
如果显示 <code>Exiting with status 0</code>, 则表示格式化成功.
</p>
</div>
</div>

<div id="outline-container-org97d9fb6" class="outline-3">
<h3 id="org97d9fb6">启动/关闭 Hadoop</h3>
<div class="outline-text-3" id="text-org97d9fb6">
</div>
<div id="outline-container-org9716476" class="outline-4">
<h4 id="org9716476">启动</h4>
<div class="outline-text-4" id="text-org9716476">
<div class="org-src-container">
<pre class="src src-Shell">./sbin/start-dfs.sh
</pre>
</div>

<p>
如果提示找不到JAVA_HOME, 且确定JAVA_HOME已设置过, 则修改配置文件: <code>etc/hadoop/hadoop-env.sh</code>, 修改其中的JAVA_HOME的值:
</p>
<div class="org-src-container">
<pre class="src src-Shell"># 原来的
JAVA_HOME=${JAVA_HOME}
# 修改为
JAVA_HOME=/usr/lib/jvm/jdk1.8.0_161
</pre>
</div>

<p>
如果启动成功, 输入 <code>jps</code> 命令后, 会显示有 <code>NameNode</code>, <code>DataNode</code>, <code>SecondaryNameNode</code> 这些进程.
</p>

<p>
成功启动后, 还可以通过Web界面(浏览器中输入<a href="http://localhost:50070">http://localhost:50070</a>)NameNode, DataNode, HDFS等信息.
</p>
</div>
</div>

<div id="outline-container-org8b2ad7c" class="outline-4">
<h4 id="org8b2ad7c">关闭</h4>
<div class="outline-text-4" id="text-org8b2ad7c">
<div class="org-src-container">
<pre class="src src-Shell">./sbin/stop-dfs.sh
</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-org9b1e44f" class="outline-3">
<h3 id="org9b1e44f">运行例子</h3>
<div class="outline-text-3" id="text-org9b1e44f">
<p>
在单机模式中读取的是本地数据, 伪分布式则使用HDFS上的数据.
</p>

<p>
在HDFS中创建用户目录:
</p>
<div class="org-src-container">
<pre class="src src-Shell">./bin/hdfs dfs -mkdir -p /user/pinvon
</pre>
</div>

<p>
当Ubuntu的用户名和HDFS上创建的用户目录名称相同时, 输入时可省略这些信息. 如要在HDFS中创建input目录, 直接输入以下命令即可:
</p>
<div class="org-src-container">
<pre class="src src-Shell">./bin/hdfs dfs -mkdir input
</pre>
</div>
<p>
此时, input目录在HDFS中的绝对路径就是: /user/pinvon/input
</p>

<p>
将hadoop的配置文件上传到HDFS作为输入:
</p>
<div class="org-src-container">
<pre class="src src-Shell">./bin/hdfs dfs -put ./etc/hadoop/*.xml input

# 查看文件列表
./bin/hdfs dfs -ls input

# 运行例子
./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar grep input output 'dfs[a-z.]+'

# 查看结果
./bin/hdfs dfs -cat output/*

# 删除输出目录
./bin/hdfs dfs -rm -r output
</pre>
</div>
</div>
</div>

<div id="outline-container-orgf8ac2ad" class="outline-3">
<h3 id="orgf8ac2ad">启动YARN</h3>
<div class="outline-text-3" id="text-orgf8ac2ad">
<p>
YARN是从MapReduce中分离出来的, 负责资源管理与任务调度. YARN运行于MapReduce之上, 提供了高可用性和高扩展性.
</p>

<p>
之前启动Hadoop, 仅仅是启动了MapReduce环境.
</p>

<p>
要启动YARN, 首先要修改配置文件.
</p>

<p>
mapred-site.xml:
</p>
<div class="org-src-container">
<pre class="src src-Shell">cd ./etc/hadoop

# 重命名
mv mapred-site.xml.template mapred-site.xml
</pre>
</div>

<p>
编辑 <code>mapred-site.xml</code>:
</p>
<div class="org-src-container">
<pre class="src src-Shell">&lt;configuration&gt;
  &lt;property&gt;
    &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
    &lt;value&gt;yarn&lt;/value&gt;
  &lt;/property&gt;
&lt;/configuration&gt;
</pre>
</div>

<p>
编辑 <code>yarn-site.xml</code>:
</p>
<div class="org-src-container">
<pre class="src src-Shell">&lt;configuration&gt;
  &lt;property&gt;
    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
  &lt;/property&gt;
&lt;/configuration&gt;
</pre>
</div>

<p>
启动YARN:
</p>
<div class="org-src-container">
<pre class="src src-Shell">./sbin/start-dfs.sh
./sbin/start-yarn.sh
./sbin/mr-jobhistory-daemon.sh start historyserver
</pre>
</div>
<p>
运行jps命令, 如果成功的话, 应该会多 <code>NodeManager</code> 和 <code>ResourceManager</code>.
</p>

<p>
开启YARN之后, 可以在Web界面查看任务的运行情况: <a href="http://localhost:8088/cluster">http://localhost:8088/cluster</a>
</p>

<p>
YARN主要是为集群提供更好的资源管理与任务调度, 但在单机上体现不出价值, 反而会使程序更慢, 因此在单机上是否开启YARN可根据自己的实际情况来.
</p>

<p>
如果不想启动YARN, 就要把 <code>mapred-site.xml</code> 重命名成 <code>mapred-site.xml.template</code>.
</p>

<p>
关闭:
</p>
<div class="org-src-container">
<pre class="src src-Shell">./sbin/mr-jobhistory-daemon.sh stop historyserver
./sbin/stop-dfs.sh
./sbin/stop-yarn.sh
</pre>
</div>
</div>
</div>
</div>

</div>
</div>
    <div>
      <div class="post-meta">
        <span title="post date" class="post-info">2018-03-10</span>
        <span title="last modification date" class="post-info">2018-03-12</span>
        <span title="tags" class="post-info"><a href="/tags/hadoop/">Hadoop</a></span>
        <span title="author" class="post-info">Pinvon</span>
      </div>
      <section>
        <h1>Comments</h1>
        <div id="disqus_thread"></div>
        <script type="text/javascript">
          //var disqus_developer = 1;
          var disqus_identifier = "/blog/2018/03/10/hadoop271+ubuntu1604安装";
          var disqus_url = "http://pinvondev.github.io/blog/2018/03/10/hadoop271+ubuntu1604安装";
          var disqus_shortname = 'pinvon';
          /* * * DON'T EDIT BELOW THIS LINE * * */
          (function() {
          var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
          dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
          (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
          })();
        </script>
        <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
        <a href="//disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
       <div id="hashover"></div>
       <script type="text/javascript" src="/hashover.php"></script>
       <noscript>You must have JavaScript enabled to use the comments.</noscript>
      </section>
      <script src="//code.jquery.com/jquery-latest.min.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/prettify/r298/prettify.js"></script>
      <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      <script src="/media/js/main.js"></script>
      <div class="footer">
        <p>Generated by <a href="http://www.gnu.org/software/emacs/">Emacs</a> 25.x (<a href="http://orgmode.org">Org mode</a> 9.x)</p>
        <p>
          Copyright &copy; 2012 - <span id="footerYear"></span> <a href="mailto:pinvon &lt;at&gt; Inspiron">Pinvon</a>
          &nbsp;&nbsp;-&nbsp;&nbsp;
          Powered by <a href="https://github.com/kelvinh/org-page" target="_blank">org-page</a>
          <script type="text/javascript">document.getElementById("footerYear").innerHTML = (new Date()).getFullYear();</script>
        </p>
      </div>
    </div>

  </body>
</html>
